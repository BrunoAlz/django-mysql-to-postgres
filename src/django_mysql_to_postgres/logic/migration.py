# src/django_mysql_to_postgres/logic/migration.py (Production Ready Version)
"""
Core logic for executing the data migration between two databases.

This module handles the physical process of connecting to the databases,
cleaning the destination tables, and transferring data row by row,
based on a pre-generated migration plan.
"""
from typing import Callable, Dict, List, Optional

from django.apps import apps
from django.db import connections, models

# Attempt to import specific psycopg2 errors for precise exception handling.
try:
    from psycopg2 import errors as psycopg2_errors
    UNDEFINED_TABLE_ERROR = psycopg2_errors.UndefinedTable
except ImportError:
    # Fallback if psycopg2 is not installed.
    UNDEFINED_TABLE_ERROR = Exception


def _default_callback(level: str, message: str):
    """A no-op callback function to avoid checking for None if no callback is provided."""
    pass


def execute_migration(
    plan: Dict[str, List[str]],
    source_db_alias: str,
    destination_db_alias: str,
    progress_callback: Optional[Callable[[str, str], None]] = None,
):
    """
    Executes the full data migration process based on the provided plan.

    This function orchestrates the cleaning of the destination database,
    the transfer of data for regular models, and the transfer of data for
    ManyToMany relationships. It is designed to be robust, handling potential
    missing tables and reporting progress via a callback.

    Args:
        plan: The migration plan dictionary generated by `analysis.py`.
              Must contain 'migration_order' and can contain 'm2m_through_models'.
        source_db_alias: The Django database alias for the source DB (e.g., 'source').
        destination_db_alias: The Django database alias for the destination DB (e.g., 'default').
        progress_callback: An optional function to call for progress updates.
                           It receives a level (e.g., 'INFO', 'SUCCESS') and a
                           message string.
    """
    callback = progress_callback or _default_callback
    migration_order = plan.get("migration_order", [])

    if not migration_order:
        callback("WARNING", "Migration plan is empty. Nothing to migrate.")
        return

    # A single connection and cursor are used for the entire transaction on the destination DB.
    with connections[destination_db_alias].cursor() as cursor:
        # Disable foreign key constraints and triggers on the destination to allow
        # data insertion in any order and to speed up the process. This is critical
        # for handling circular dependencies.
        callback("INFO", "Disabling triggers and foreign keys on destination DB...")
        cursor.execute("SET session_replication_role = 'replica';")

        # --- PHASE 1: CLEANUP ---
        # Tables are truncated in reverse dependency order as a safeguard.
        # TRUNCATE is used as it's much faster than DELETE and resets sequences.
        callback("INFO", "--- PHASE 1: Cleaning destination tables... ---")
        for model_label in reversed(migration_order):
            try:
                model = apps.get_model(model_label)
                table_name = model._meta.db_table
                callback("INFO", f"Cleaning table: {table_name}")
                cursor.execute(
                    f'TRUNCATE TABLE "{table_name}" RESTART IDENTITY CASCADE;')
            except UNDEFINED_TABLE_ERROR:
                callback(
                    "WARNING", f"Table '{table_name}' not found in destination. Skipping cleanup.")
            except Exception as e:
                callback(
                    "ERROR", f"Unexpected error cleaning {table_name}: {e}")
                # Re-enable constraints on failure
                cursor.execute("SET session_replication_role = 'origin';")
                raise

        # --- PHASE 2: DATA MIGRATION ---
        # Models are migrated in the topologically sorted order.
        callback("INFO", "\n--- PHASE 2: Migrating model data... ---")
        migrated_models_classes = []
        for model_label in migration_order:
            model = apps.get_model(model_label)
            migrated_models_classes.append(model)

            callback(
                "INFO", f"\nMigrating {model._meta.verbose_name_plural}...")

            # Store original states of auto_now/auto_now_add fields
            original_states = {}
            for field in model._meta.local_fields:
                if isinstance(field, (models.DateTimeField, models.DateField)):
                    if field.auto_now or field.auto_now_add:
                        original_states[field.name] = {
                            "auto_now": field.auto_now,
                            "auto_now_add": field.auto_now_add,
                        }
                        field.auto_now = False
                        field.auto_now_add = False

            try:
                # Read from source and write to destination
                source_items = list(model.objects.using(source_db_alias).all())
                count = len(source_items)

                if count == 0:
                    callback("INFO", "No items to migrate.")
                    continue

                callback(
                    "INFO", f"Found {count} items. Inserting into destination...")
                model.objects.using(destination_db_alias).bulk_create(
                    source_items, batch_size=1000)
                callback("SUCCESS", "Success!")

            except Exception as e:
                # Handle errors gracefully
                # MySQL or Postgres 'table not found'
                if ("1146" in str(e)) or ("UndefinedTable" in str(e.__class__.__name__)):
                    callback(
                        "WARNING", f"Table for '{model_label}' not found. Skipping.")
                else:
                    callback(
                        "ERROR", f"Error during data migration for {model_label}: {e}")
                    cursor.execute("SET session_replication_role = 'origin';")
                    raise
            finally:
                # CRITICAL: Always restore the model's fields to their original state
                if original_states:
                    for field in model._meta.local_fields:
                        if field.name in original_states:
                            field.auto_now = original_states[field.name]['auto_now']
                            field.auto_now_add = original_states[field.name]['auto_now_add']
                    callback(
                        "INFO", f"Restored auto-timestamp fields for {model_label}")

        # --- PHASE 3: M2M MIGRATION (FINAL, ROBUST VERSION) ---
        # This phase now correctly uses the pre-calculated plan for M2M tables,
        # avoiding rediscovery and potential errors.
        callback("INFO", "\n--- PHASE 3: Migrating ManyToMany relationships... ---")
        m2m_model_labels = plan.get("m2m_through_models", [])

        if not m2m_model_labels:
            callback("INFO", "No custom ManyToMany models to migrate.")
        else:
            for model_label in m2m_model_labels:
                callback("INFO", f"\nProcessing M2M table: {model_label}")
                try:
                    m2m_model = apps.get_model(model_label)
                    m2m_relations = list(
                        m2m_model.objects.using(source_db_alias).all())

                    if m2m_relations:
                        m2m_model.objects.using(destination_db_alias).bulk_create(
                            m2m_relations, batch_size=2000
                        )
                        callback(
                            "SUCCESS", f"Success: {len(m2m_relations)} relationships migrated for {model_label}.")
                    else:
                        callback(
                            "INFO", f"No relationships to migrate for {model_label}.")
                except Exception as e:
                    callback(
                        "WARNING", f"Could not migrate M2M for {model_label}: {e}")

        # --- FINALIZATION ---
        # Re-enable all constraints and triggers.
        callback(
            "INFO", "\n--- Finalizing: Re-enabling triggers and resetting sequences... ---")
        cursor.execute("SET session_replication_role = 'origin';")

        # As a final safeguard, update all primary key sequences to the max current ID.
        # This prevents ID conflicts if new rows are created after migration.
        for model in migrated_models_classes:
            try:
                table_name = model._meta.db_table
                pk_name = model._meta.pk.name
                if isinstance(model._meta.pk, (models.AutoField, models.BigAutoField)):
                    sql = f"""SELECT setval(pg_get_serial_sequence('"{table_name}"', '{pk_name}'), COALESCE(MAX("{pk_name}"), 1), MAX("{pk_name}") IS NOT NULL) FROM "{table_name}";"""
                    cursor.execute(sql)
            except (Exception, UNDEFINED_TABLE_ERROR):
                # It's safe to ignore errors here (e.g., table not found, or no PK sequence).
                pass

    callback("SUCCESS", "\n\nMigration process completed successfully!")
    callback("INFO", "All data has been migrated and constraints have been restored.")
